<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Building Machine Learning Pipelines in Python &mdash; Paolo Mascia</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="article.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
</head>
<body>

    <nav class="navbar scrolled">
        <div class="container">
            <a href="index.html" class="nav-logo">
                <span class="logo-accent">&gt;</span> paolo.mascia
            </a>
            <div class="nav-links">
                <a href="index.html#about">About</a>
                <a href="index.html#projects">Projects</a>
                <a href="ai-tech-insights.html">AI Tech Insights</a>
                <a href="cybersecurity-tech-insights.html">Cybersecurity</a>
                <a href="golang-tech-insights.html">Go</a>
                <a href="index.html#contact">Contact</a>
            </div>
        </div>
    </nav>

    <article class="article">
        <div class="container">
            <div class="article-layout">
                <div class="article-main">
                    <header class="article-header">
                        <a href="ai-tech-insights.html" class="back-link">&larr; Back to Tech Insights</a>
                        <div class="post-meta">
                            <span class="post-date">Oct 2025</span>
                            <span class="post-reading">10 min read</span>
                        </div>
                        <h1>Building Machine Learning Pipelines in Python</h1>
                        <div class="post-tags">
                            <span>Pipelines</span>
                            <span>Scikit-Learn</span>
                            <span>Python</span>
                        </div>
                    </header>

                    <div class="article-body">
                        <p class="lead">A Pipeline in scikit-learn chains preprocessing and modeling steps into one reusable workflow. It automates transformations, prevents data leakage, and integrates seamlessly with cross-validation and hyperparameter tuning.</p>

                        <h2>What is a Machine Learning Pipeline?</h2>
                        <p>A machine learning pipeline is a sequential chain of data processing and modeling steps bundled into a single estimator. Instead of manually applying each transformation before training, pipelines let you define the entire workflow once and reuse it consistently.</p>
                        <p>Key benefits include:</p>
                        <ul>
                            <li><strong>Automation</strong> &mdash; Apply all preprocessing steps automatically at fit and predict time.</li>
                            <li><strong>Consistency</strong> &mdash; Guarantee the same transformations are applied to training and test data, preventing data leakage.</li>
                            <li><strong>Clean code</strong> &mdash; Replace scattered transformation calls with a single, readable object.</li>
                            <li><strong>Integration</strong> &mdash; Pipelines work natively with cross-validation, grid search, and other scikit-learn utilities.</li>
                        </ul>

                        <h2>Basic Pipeline Structure</h2>
                        <p>The simplest pipeline chains a scaler and a classifier. Each step is a <code>(name, estimator)</code> tuple. When you call <code>fit()</code>, every transformer runs <code>fit_transform()</code> in order, and the final estimator runs <code>fit()</code>.</p>
                        <pre><code class="language-python">from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split

X, y = load_wine(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)

pipe = Pipeline([
    ("scaler", StandardScaler()),
    ("model", LogisticRegression(max_iter=1000))
])

pipe.fit(X_train, y_train)
print("Test Accuracy:", pipe.score(X_test, y_test))</code></pre>

                        <h2>Preprocessing Mixed Feature Types</h2>
                        <p>Real-world datasets often contain both numerical and categorical columns. <code>ColumnTransformer</code> lets you apply different preprocessing to each group, then merge the results into a single feature matrix.</p>
                        <pre><code class="language-python">import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline

data = pd.DataFrame({
    "age": [25, 32, 47, 51, 62],
    "income": [50000, 64000, 120000, 110000, 150000],
    "gender": ["M", "F", "F", "M", "M"],
    "bought": [0, 0, 1, 1, 1]
})

X = data[["age", "income", "gender"]]
y = data["bought"]

num_features = ["age", "income"]
cat_features = ["gender"]

preprocessor = ColumnTransformer([
    ("num", StandardScaler(), num_features),
    ("cat", OneHotEncoder(drop="first"), cat_features)
])

pipe = Pipeline([
    ("preprocess", preprocessor),
    ("model", LogisticRegression())
])

pipe.fit(X, y)
print("Coefficients:", pipe.named_steps["model"].coef_)</code></pre>

                        <h2>Cross-Validation and Grid Search</h2>
                        <p>Pipelines integrate directly with <code>GridSearchCV</code>. Use the <code>step_name__param</code> syntax to target hyperparameters inside any pipeline step.</p>
                        <pre><code class="language-python">from sklearn.model_selection import GridSearchCV

param_grid = {
    "model__C": [0.1, 1, 10],
    "model__penalty": ["l2"]
}

grid = GridSearchCV(pipe, param_grid, cv=5, scoring="accuracy")
grid.fit(X, y)
print("Best parameters:", grid.best_params_)
print("Best CV score:", round(grid.best_score_, 3))</code></pre>

                        <h2>Handling Missing Values</h2>
                        <p>Missing data is a common issue. By placing an imputer as the first pipeline step, every call to <code>fit()</code> or <code>predict()</code> handles NaN values automatically.</p>
                        <pre><code class="language-python">import numpy as np
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import Pipeline

X = np.array([[1, 2], [np.nan, 3], [7, 6], [8, np.nan]])
y = np.array([1.2, 1.8, 5.5, 6.0])

pipe = Pipeline([
    ("imputer", SimpleImputer(strategy="mean")),
    ("scaler", StandardScaler()),
    ("model", LinearRegression())
])

pipe.fit(X, y)
print("Predictions:", pipe.predict(X))</code></pre>

                        <h2>Feature Selection Within Pipelines</h2>
                        <p>Feature selection can be embedded as a pipeline step, ensuring that only the most informative features reach the model. This is especially useful when combined with cross-validation.</p>
                        <pre><code class="language-python">from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.linear_model import Ridge
from sklearn.pipeline import Pipeline
from sklearn.datasets import load_diabetes
from sklearn.model_selection import cross_val_score

X, y = load_diabetes(return_X_y=True)

pipe = Pipeline([
    ("select", SelectKBest(f_regression, k=5)),
    ("model", Ridge(alpha=1.0))
])

scores = cross_val_score(pipe, X, y, cv=5, scoring="r2")
print("Mean CV R2:", round(scores.mean(), 3))</code></pre>

                        <h2>Custom Transformers</h2>
                        <p>You can build your own transformer by subclassing <code>BaseEstimator</code> and <code>TransformerMixin</code>. This lets you inject any custom logic into a pipeline.</p>
                        <pre><code class="language-python">from sklearn.base import BaseEstimator, TransformerMixin
import numpy as np

class LogTransformer(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        return self
    def transform(self, X):
        return np.log1p(X)

from sklearn.linear_model import LinearRegression
from sklearn.pipeline import Pipeline

pipe = Pipeline([
    ("log", LogTransformer()),
    ("model", LinearRegression())
])

X = np.array([[1], [10], [100]])
y = np.array([2, 3, 5])
pipe.fit(X, y)
print("Predictions:", pipe.predict(X))</code></pre>

                        <h2>Exporting and Deploying Pipelines</h2>
                        <p>Once trained, a pipeline can be serialized with <code>joblib</code> and loaded later for inference in production. The entire preprocessing and model logic travels together in a single file.</p>
                        <pre><code class="language-python">import joblib

joblib.dump(pipe, "ml_pipeline.pkl")
loaded_pipe = joblib.load("ml_pipeline.pkl")
print("Loaded pipeline prediction:", loaded_pipe.predict(X[:3]))</code></pre>

                        <h2>Key Takeaways</h2>
                        <ul>
                            <li>Pipelines chain preprocessing and modeling into a single, reusable estimator.</li>
                            <li>Use <code>ColumnTransformer</code> to handle mixed feature types cleanly.</li>
                            <li>Pipelines prevent data leakage by applying transformations within each cross-validation fold.</li>
                            <li>Grid search works seamlessly with pipelines using the <code>step__param</code> naming convention.</li>
                            <li>Custom transformers let you inject any domain-specific logic into the workflow.</li>
                            <li>Serialize trained pipelines with <code>joblib</code> for easy deployment.</li>
                        </ul>
                    </div>
                </div>

                <aside class="article-sidebar">
                    <div class="sidebar-author">
                        <img src="images/pm.png" alt="Paolo Mascia" class="sidebar-author-photo">
                        <div class="sidebar-author-name">Paolo Mascia</div>
                        <div class="sidebar-author-role">AI &amp; Cloud Architect</div>
                        <p class="sidebar-author-bio">25+ years designing large-scale distributed systems. Specialized in Generative AI, AI Agents, and cloud-native architectures.</p>
                        <div class="sidebar-author-links">
                            <a href="https://www.linkedin.com/in/paolo-mascia-italy" target="_blank" aria-label="LinkedIn">
                                <svg viewBox="0 0 24 24"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 01-2.063-2.065 2.064 2.064 0 112.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>
                            </a>
                            <a href="https://github.com/paolomascia" target="_blank" aria-label="GitHub">
                                <svg viewBox="0 0 24 24"><path d="M12 0C5.374 0 0 5.373 0 12c0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/></svg>
                            </a>
                            <a href="https://www.kaggle.com/paolomascia" target="_blank" aria-label="Kaggle">
                                <svg viewBox="0 0 24 24"><path d="M18.825 23.859c-.022.092-.117.141-.281.141h-3.139c-.187 0-.351-.082-.492-.248l-5.178-6.589-1.448 1.374v5.111c0 .235-.117.352-.351.352H5.505c-.236 0-.354-.117-.354-.352V.353c0-.233.118-.353.354-.353h2.431c.234 0 .351.12.351.353v14.343l6.203-6.272c.165-.165.33-.246.495-.246h3.239c.144 0 .236.06.281.18.046.149.034.233-.036.315l-6.555 6.344 6.836 8.507c.095.104.117.208.075.378z"/></svg>
                            </a>
                        </div>
                    </div>
                    <div class="sidebar-box">
                        <h4>More Articles</h4>
                        <a href="post-regularization.html" class="sidebar-link">
                            <span class="sidebar-link-tag">Linear Regression</span>
                            <div class="sidebar-link-title">Regularization: Ridge, Lasso, and Elastic Net</div>
                            <span class="sidebar-link-meta">Oct 2025</span>
                        </a>
                        <a href="post-random-forest.html" class="sidebar-link">
                            <span class="sidebar-link-tag">Model Evaluation</span>
                            <div class="sidebar-link-title">Random Forest Model Evaluation</div>
                            <span class="sidebar-link-meta">Oct 2025</span>
                        </a>
                        <a href="post-kmeans.html" class="sidebar-link">
                            <span class="sidebar-link-tag">K-Means</span>
                            <div class="sidebar-link-title">K-Means Clustering Evaluation</div>
                            <span class="sidebar-link-meta">Oct 2025</span>
                        </a>
                        <a href="post-svm.html" class="sidebar-link">
                            <span class="sidebar-link-tag">Classification</span>
                            <div class="sidebar-link-title">Support Vector Machines in Python</div>
                            <span class="sidebar-link-meta">Oct 2025</span>
                        </a>
                        <a href="post-pca.html" class="sidebar-link">
                            <span class="sidebar-link-tag">PCA</span>
                            <div class="sidebar-link-title">Principal Component Analysis (PCA) in Python</div>
                            <span class="sidebar-link-meta">Oct 2025</span>
                        </a>
                    </div>
                </aside>
            </div>
        </div>
    </article>

    <footer class="footer">
        <div class="container">
            <p>&copy; 2025 Paolo Mascia. Built with curiosity and too much coffee.</p>
        </div>
    </footer>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
</body>
</html>