<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Autoencoders: Learning Efficient Data Representations — Paolo Mascia</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="article.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
</head>
<body>

    <nav class="navbar scrolled">
        <div class="container">
            <a href="index.html" class="nav-logo">
                <span class="logo-accent">&gt;</span> paolo.mascia
            </a>
            <div class="nav-links">
                <a href="index.html#about">About</a>
                <a href="index.html#projects">Projects</a>
                <a href="ai-tech-insights.html">AI Tech Insights</a>
                <a href="cybersecurity-tech-insights.html">Cybersecurity</a>
                <a href="golang-tech-insights.html">Go</a>
                <a href="index.html#contact">Contact</a>
            </div>
        </div>
    </nav>

    <article class="article">
        <div class="container">
            <div class="article-layout">
                <div class="article-main">
                    <header class="article-header">
                        <a href="ai-tech-insights.html" class="back-link">&larr; Back to Tech Insights</a>
                        <div class="post-meta">
                            <span class="post-date">Dec 2024</span>
                            <span class="post-reading">5 min read</span>
                        </div>
                        <h1>Autoencoders: Learning Efficient Data Representations</h1>
                        <div class="post-tags">
                            <span>Autoencoders</span>
                            <span>Unsupervised Learning</span>
                            <span>Deep Learning</span>
                        </div>
                    </header>

                    <div class="article-body">
                        <p class="lead">Autoencoders are a type of unsupervised neural network designed to learn compressed representations of input data. They play a crucial role in tasks like dimensionality reduction, denoising, anomaly detection, and feature learning.</p>

                        <p>Unlike traditional supervised models, autoencoders don't predict labels. Instead, they try to reconstruct their input as closely as possible — forcing the model to learn meaningful internal representations of the data.</p>

                        <h2>How Autoencoders Work</h2>
                        <p>An autoencoder consists of two main parts:</p>
                        <ul>
                            <li><strong>Encoder:</strong> Compresses the input into a lower-dimensional representation (called the <em>latent space</em> or <em>code</em>).</li>
                            <li><strong>Decoder:</strong> Reconstructs the original input from the latent space.</li>
                        </ul>
                        <pre><code class="language-python">Input → [Encoder] → Latent Representation → [Decoder] → Output (Reconstruction)</code></pre>
                        <p>The goal is to minimize the reconstruction loss, usually the <strong>Mean Squared Error (MSE)</strong> between input and output.</p>

                        <h2>Mathematical Formulation</h2>
                        <p>Given input <code>x</code>:</p>
                        <pre><code class="language-python">z = f(W_1 * x + b_1)          → encoding
x' = g(W_2 * z + b_2)         → decoding
Loss = ||x - x'||^2</code></pre>
                        <p>Here, <code>f</code> and <code>g</code> are activation functions (like ReLU or sigmoid), and <code>z</code> is the compressed latent vector.</p>

                        <h2>Building a Simple Autoencoder in Keras</h2>
                        <pre><code class="language-python">from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.datasets import mnist
import numpy as np
import matplotlib.pyplot as plt

# Load MNIST dataset
(X_train, _), (X_test, _) = mnist.load_data()
X_train = X_train.astype('float32') / 255.0
X_test = X_test.astype('float32') / 255.0
X_train = X_train.reshape((len(X_train), -1))
X_test = X_test.reshape((len(X_test), -1))

# Encoder
input_dim = X_train.shape[1]
encoding_dim = 64

input_layer = Input(shape=(input_dim,))
encoded = Dense(encoding_dim, activation='relu')(input_layer)

# Decoder
decoded = Dense(input_dim, activation='sigmoid')(encoded)

# Autoencoder model
autoencoder = Model(input_layer, decoded)
autoencoder.compile(optimizer='adam', loss='mse')
autoencoder.summary()</code></pre>

                        <h2>Training the Autoencoder</h2>
                        <pre><code class="language-python">history = autoencoder.fit(
    X_train, X_train,
    epochs=20,
    batch_size=256,
    shuffle=True,
    validation_data=(X_test, X_test)
)</code></pre>
                        <p>Here, the model learns to reproduce its input. The encoder compresses information into 64 dimensions, while the decoder learns to reconstruct the digits.</p>

                        <h2>Visualizing Reconstruction</h2>
                        <pre><code class="language-python">decoded_imgs = autoencoder.predict(X_test)

n = 5
plt.figure(figsize=(10, 4))
for i in range(n):
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(X_test[i].reshape(28, 28), cmap='gray')
    plt.axis('off')

    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(28, 28), cmap='gray')
    plt.axis('off')
plt.suptitle("Original vs Reconstructed Images")
plt.show()</code></pre>
                        <p>You'll notice that even with a small latent space, the network captures the general shape of the digits while ignoring noise.</p>

                        <h2>Extracting the Encoder</h2>
                        <p>Once trained, you can use the encoder part to obtain compressed features:</p>
                        <pre><code class="language-python">encoder = Model(input_layer, encoded)
encoded_imgs = encoder.predict(X_test)
print("Encoded shape:", encoded_imgs.shape)</code></pre>
                        <p>These compact representations are useful for visualization, clustering, or as input features for other models.</p>

                        <h2>Denoising Autoencoder</h2>
                        <p>A <strong>denoising autoencoder</strong> learns to remove noise from corrupted input data. During training, the input is intentionally noised, but the model learns to reconstruct the clean version.</p>
                        <pre><code class="language-python">noise_factor = 0.3
X_train_noisy = X_train + noise_factor * np.random.normal(
    loc=0.0, scale=1.0, size=X_train.shape)
X_test_noisy = X_test + noise_factor * np.random.normal(
    loc=0.0, scale=1.0, size=X_test.shape)
X_train_noisy = np.clip(X_train_noisy, 0., 1.)
X_test_noisy = np.clip(X_test_noisy, 0., 1.)

autoencoder.fit(X_train_noisy, X_train,
    epochs=10, batch_size=256,
    validation_data=(X_test_noisy, X_test))</code></pre>
                        <p>This technique is especially effective in image preprocessing and signal restoration.</p>

                        <h2>Regularized Autoencoders</h2>
                        <p>To prevent the network from simply copying inputs, we can apply constraints:</p>
                        <ul>
                            <li><strong>Sparse Autoencoder:</strong> adds L1 regularization to encourage sparsity in activations.</li>
                            <li><strong>Denoising Autoencoder:</strong> trains to recover clean input from noisy data.</li>
                            <li><strong>Contractive Autoencoder:</strong> penalizes sensitivity to small input changes.</li>
                        </ul>
                        <pre><code class="language-python">from tensorflow.keras import regularizers

encoded = Dense(encoding_dim, activation='relu',
    activity_regularizer=regularizers.l1(1e-4))(input_layer)</code></pre>

                        <h2>Variational Autoencoder (VAE)</h2>
                        <p>The <strong>Variational Autoencoder</strong> (VAE) extends standard autoencoders by learning a <em>probabilistic</em> latent space. Instead of encoding a fixed vector, it learns a distribution over the latent variables, allowing for generative modeling.</p>
                        <p>VAEs can generate new, unseen samples by sampling from the latent space — making them a bridge between autoencoders and generative models like GANs.</p>

                        <h2>Applications of Autoencoders</h2>
                        <ul>
                            <li><strong>Dimensionality Reduction:</strong> a nonlinear alternative to PCA.</li>
                            <li><strong>Denoising:</strong> remove noise from images, audio, or signals.</li>
                            <li><strong>Anomaly Detection:</strong> high reconstruction error indicates outliers.</li>
                            <li><strong>Pretraining:</strong> initialize weights for deep networks.</li>
                            <li><strong>Generative Modeling:</strong> using VAEs for new sample generation.</li>
                        </ul>

                        <h2>Example: Anomaly Detection with Autoencoders</h2>
                        <p>If the model is trained on normal data, it will reconstruct anomalies poorly — resulting in higher reconstruction errors.</p>
                        <pre><code class="language-python">reconstructions = autoencoder.predict(X_test)
mse = np.mean(np.power(X_test - reconstructions, 2), axis=1)

threshold = np.mean(mse) + 3*np.std(mse)
anomalies = mse > threshold
print("Detected anomalies:", np.sum(anomalies))</code></pre>

                        <h2>Key Takeaways</h2>
                        <ul>
                            <li>Autoencoders compress data into meaningful lower-dimensional representations.</li>
                            <li>Denoising and sparse autoencoders improve robustness and interpretability.</li>
                            <li>VAEs extend autoencoders to the generative modeling domain.</li>
                            <li>They are powerful tools for feature extraction, anomaly detection, and unsupervised learning.</li>
                        </ul>
                    </div>
                </div>

                <aside class="article-sidebar">
                    <div class="sidebar-author">
                        <img src="images/pm.png" alt="Paolo Mascia" class="sidebar-author-photo">
                        <div class="sidebar-author-name">Paolo Mascia</div>
                        <div class="sidebar-author-role">AI & Cloud Architect</div>
                        <p class="sidebar-author-bio">25+ years designing large-scale distributed systems. Specialized in Generative AI, AI Agents, and cloud-native architectures.</p>
                        <div class="sidebar-author-links">
                            <a href="https://www.linkedin.com/in/paolo-mascia-italy" target="_blank" aria-label="LinkedIn">
                                <svg viewBox="0 0 24 24"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 01-2.063-2.065 2.064 2.064 0 112.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>
                            </a>
                            <a href="https://github.com/paolomascia" target="_blank" aria-label="GitHub">
                                <svg viewBox="0 0 24 24"><path d="M12 0C5.374 0 0 5.373 0 12c0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/></svg>
                            </a>
                            <a href="https://www.kaggle.com/paolomascia" target="_blank" aria-label="Kaggle">
                                <svg viewBox="0 0 24 24"><path d="M18.825 23.859c-.022.092-.117.141-.281.141h-3.139c-.187 0-.351-.082-.492-.248l-5.178-6.589-1.448 1.374v5.111c0 .235-.117.352-.351.352H5.505c-.236 0-.354-.117-.354-.352V.353c0-.233.118-.353.354-.353h2.431c.234 0 .351.12.351.353v14.343l6.203-6.272c.165-.165.33-.246.495-.246h3.239c.144 0 .236.06.281.18.046.149.034.233-.036.315l-6.555 6.344 6.836 8.507c.095.104.117.208.075.378z"/></svg>
                            </a>
                        </div>
                    </div>
                    <div class="sidebar-box">
                        <h4>More Articles</h4>
                        <a href="post-transformers.html" class="sidebar-link">
                            <span class="sidebar-link-tag">Transformers</span>
                            <div class="sidebar-link-title">Transformers: The Architecture That Revolutionized Deep Learning</div>
                            <span class="sidebar-link-meta">Mar 2025</span>
                        </a>
                        <a href="post-cnn.html" class="sidebar-link">
                            <span class="sidebar-link-tag">CNN</span>
                            <div class="sidebar-link-title">Convolutional Neural Networks (CNNs): The Brains Behind Computer Vision</div>
                            <span class="sidebar-link-meta">Jan 2025</span>
                        </a>
                        <a href="post-rnn.html" class="sidebar-link">
                            <span class="sidebar-link-tag">RNN</span>
                            <div class="sidebar-link-title">Recurrent Neural Networks (RNNs): Learning from Sequences</div>
                            <span class="sidebar-link-meta">Apr 2025</span>
                        </a>
                        <a href="post-pca.html" class="sidebar-link">
                            <span class="sidebar-link-tag">PCA</span>
                            <div class="sidebar-link-title">Principal Component Analysis (PCA) in Python</div>
                            <span class="sidebar-link-meta">May 2024</span>
                        </a>
                        <a href="post-tsne-umap.html" class="sidebar-link">
                            <span class="sidebar-link-tag">Dimension Reduction</span>
                            <div class="sidebar-link-title">t-SNE and UMAP in Python</div>
                            <span class="sidebar-link-meta">Jul 2024</span>
                        </a>
                    </div>
                </aside>
            </div>
        </div>
    </article>

    <footer class="footer">
        <div class="container">
            <p>&copy; 2025 Paolo Mascia. Built with curiosity and too much coffee.</p>
        </div>
    </footer>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
</body>
</html>
